name: "@Desktop â€¢ Test App (external)"
run-name: "@Desktop â€¢ Test App (external) triggered by ${{ inputs.login }} ${{ format('on ref {0}', github.ref_name) }}"

on:
  workflow_dispatch:
    inputs:
      ref:
        description: |
          If you run this manually, and want to run on a PR, the correct ref should be refs/pull/{PR_NUMBER}/merge to
          have the "normal" scenario involving checking out a merge commit between your branch and the base branch.
          If you want to run only on a branch or specific commit, you can use either the sha or the branch name instead (prefer the first verion for PRs).
        required: false
      login:
        description: The GitHub username that triggered the workflow
        required: false
      base_ref:
        description: The base branch to merge the head into when checking out the code
        required: false

concurrency:
  group: ${{ github.workflow }}-${{ github.ref_name != 'develop' && github.ref || github.run_id }}
  cancel-in-progress: true

jobs:
  codechecks:
    name: "Ledger Live code checks"
    env:
      NODE_OPTIONS: "--max-old-space-size=7168"
      FORCE_COLOR: 3
      CI_OS: ubuntu-latest
    runs-on: ubuntu-latest
    steps:
      - uses: LedgerHQ/ledger-live/tools/actions/composites/checkout-merge@develop
        with:
          ref: ${{ github.ref_name }}
          base: ${{ inputs.base_ref }}
      - name: Setup the toolchain
        uses: ./tools/actions/composites/setup-toolchain
        with:
          install_dotnet: true
      - uses: ./tools/actions/composites/setup-test-desktop
        id: setup-test-desktop
        with:
          skip_builds: true
      - name: lint
        run: pnpm desktop lint:ci
      - name: prettier
        run: pnpm desktop prettier:check
      - name: typecheck
        run: pnpm desktop typecheck
      - uses: actions/upload-artifact@v3
        name: upload eslint json output
        if: always()
        with:
          name: lint
          path: ${{ github.workspace }}/apps/ledger-live-desktop/lint.json

  deadcodecheck:
    name: "Desktop deadcode check"
    env:
      NODE_OPTIONS: "--max-old-space-size=7168"
      FORCE_COLOR: 3
      CI_OS: ubuntu-latest
    runs-on: ubuntu-latest
    steps:
      - uses: LedgerHQ/ledger-live/tools/actions/composites/checkout-merge@develop
        with:
          ref: ${{ github.ref_name }}
          base: ${{ inputs.base_ref }}
      - name: Setup the toolchain
        uses: ./tools/actions/composites/setup-toolchain
      - uses: ./tools/actions/composites/setup-test-desktop
        id: setup-test-desktop
        with:
          skip_builds: true
      - name: check for dead code
        run: pnpm desktop unimported
        shell: bash

  unit-tests:
    name: "Ledger Live Desktop Unit Tests"
    env:
      NODE_OPTIONS: "--max-old-space-size=7168"
      FORCE_COLOR: 3
      CI_OS: ubuntu-latest
    runs-on: ubuntu-latest
    steps:
      - uses: LedgerHQ/ledger-live/tools/actions/composites/checkout-merge@develop
        with:
          ref: ${{ github.ref_name }}
          base: ${{ inputs.base_ref }}
      - name: Setup the toolchain
        uses: ./tools/actions/composites/setup-toolchain
      - uses: ./tools/actions/composites/setup-test-desktop
        id: setup-test-desktop
        with:
          skip_builds: true
      - name: Run unit tests
        run: pnpm desktop test:jest

  e2e-tests-linux:
    name: "Live Desktop Tests (Ubuntu)"
    env:
      NODE_OPTIONS: "--max-old-space-size=7168"
      FORCE_COLOR: 3
      CI_OS: ubuntu-latest
      PLAYWRIGHT_SKIP_BROWSER_DOWNLOAD: 1
      # DEBUG: "pw:browser*"
      # DEBUG_LOGS: 1
    runs-on: ubuntu-latest
    outputs:
      status: ${{ steps.tests.outcome }}
    steps:
      - uses: LedgerHQ/ledger-live/tools/actions/composites/checkout-merge@develop
        with:
          ref: ${{ github.ref_name }}
          base: ${{ inputs.base_ref }}
      - name: Setup the toolchain
        uses: ./tools/actions/composites/setup-toolchain
      - uses: ./tools/actions/composites/setup-test-desktop
        id: setup-test-desktop
        with:
          skip_ruby: true
          install_playwright: true
      - name: Run playwright tests [Linux => xvfb-run]
        id: tests
        run: |
          xvfb-run --auto-servernum --server-args="-screen 0 1280x960x24" -- pnpm desktop test:playwright:smoke
      # - name: upload diffs to s3
      #   if: always() && !cancelled()
      #   uses: ./tools/actions/upload-images
      #   id: s3
      #   with:
      #     path: apps/ledger-live-desktop/tests/artifacts/test-results
      #     workspace: ${{ github.workspace }}
      #     os: linux
      #     group-name: ${{ github.ref_name }}-${{ github.run_id }}-${{ github.run_number }}
      #   env:
      #     AWS_ACCESS_KEY_ID: ${{ secrets.AWS_S3_SCREENSHOTS_ACCESS_KEY }}
      #     AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_S3_SCREENSHOTS_SECRET_ACCESS_KEY }}
      - name: upload ci suggested screenshots
        if: always() && !cancelled()
        uses: actions/upload-artifact@v3
        with:
          name: images
          path: images-linux.json
      - name: Upload playwright test results [On Failure]
        uses: actions/upload-artifact@v3
        if: failure() && !cancelled()
        with:
          name: playwright-results-linux
          path: |
            apps/ledger-live-desktop/tests/artifacts/test-results
            apps/ledger-live-desktop/tests/artifacts/html-report
            apps/ledger-live-desktop/tests/artifacts/coverage
            apps/ledger-live-desktop/tests/artifacts/videos
            apps/ledger-live-desktop/tests/artifacts/logs
      - name: Upload Allure Report
        if: always()
        uses: actions/upload-artifact@v3
        with:
          name: allure-results-linux
          path: apps/ledger-live-desktop/allure-results

  report:
    needs: [codechecks, deadcodecheck, unit-tests, e2e-tests-linux]
    runs-on: ubuntu-latest
    if: always() && !cancelled() && github.event_name == 'workflow_dispatch'
    steps:
      - uses: LedgerHQ/ledger-live/tools/actions/composites/checkout-merge@develop
        with:
          ref: ${{ github.ref_name }}
          base: ${{ inputs.base_ref }}
      - name: "download linter results"
        uses: actions/download-artifact@v3
        with:
          name: lint
      - name: download images artifacts
        uses: actions/download-artifact@v3
        with:
          name: images
      - name: parse images
        uses: actions/github-script@v6
        with:
          script: |
            const fs = require("fs");
            const files = ["images-linux"];
            let result = {};
            for (const file of files) {
              try {
                const raw = JSON.parse(fs.readFileSync("${{github.workspace}}/" + file + ".json"));
                const key = file.replace("images-", "").replace("-latest", "").trim()
                result[key] = raw;
              } catch (err) {
                console.log(err);
              }
            }
            fs.writeFileSync("./images.json", JSON.stringify(result, null, 2));
      - name: prepare comment with screenshots
        id: comment
        uses: ./tools/actions/prepare-comment-screenshots
        with:
          images: images.json
          no-actor: true
      - uses: actions/github-script@v6
        name: prepare status
        id: status
        with:
          script: |
            const fs = require("fs");
            const path = require("path");

            const [ owner, repo ] = "${{ github.repository }}".split("/");

            const jobs = await github.paginate(github.rest.actions.listJobsForWorkflowRunAttempt, {
              owner,
              repo,
              run_id: "${{ github.run_id }}",
              attempt_number: "${{ github.run_attempt }}",
            });

            const findJobUrl = os =>
              jobs.find(job => job.name == `Live Desktop Tests (${os})`)?.html_url;

            const keys = {
              linux: {
                symbol: "ðŸ§",
                name: "Linux",
                jobUrl: findJobUrl("Linux")
              },
            };

            const typecheck = {
              pass: ${{ needs.codechecks.result == 'success' }},
              status: "${{ needs.codechecks.result }}",
            };

            const unitTests = {
              pass: ${{ needs.unit-tests.result == 'success' }},
              status: "${{ needs.unit-tests.result }}",
            };

            const deadcodecheck = {
              pass: ${{ needs.deadcodecheck.result == 'success' }},
            };

            const report = {
              linux: {
                pass: ${{ needs.e2e-tests-linux.outputs.status == 'success' }},
                status: "${{ needs.e2e-tests-linux.outputs.status }}",
              },
            };

            let summary = `### TypeCheck

            ${typecheck.pass ? "Typechecks are fine" : "Unfortunately typechecks did not pass"}
              - ${typecheck.pass ? "âœ…" : "âŒ"} **Type checks** ended with status \`${typecheck.status}\`

            ### Dead Code Check
            ${deadcodecheck.pass ? "Dead code checks are fine" : "Unfortunately, dead code checks did not pass. Try \`pnpm desktop unimported\` in apps/ledger-live-desktop"}
              - ${deadcodecheck.pass ? "âœ…" : "âŒ"}

            ### Unit Tests (Jest)
            ${unitTests.pass ? "Unit tests are fine" : "Unit tests did not pass"}
              - ${unitTests.pass ? "âœ…" : "âŒ"} **Unit tests** ended with status \`${unitTests.status}\`

            ### Screenshot Tests (Playwright)
            `

            summary += `|`

            const reportKeys = Object.keys(report);

            reportKeys.forEach((k) => {
              summary += ` [${keys[k].symbol} ${keys[k].name}](${keys[k].jobUrl}) |`;
            });

            summary += `
            |`;

            for (let i = 0; i < reportKeys.length; i++) {
              summary += ` :--: |`;
            }

            summary += `
            |`;

            Object.entries(report).forEach(([os, values]) => {
              summary += ` ${values.pass ? "âœ…" : "âŒ"} (${values.status}) |`;
            });

            summary += `
            ${{ steps.comment.outputs.body }}
            `

            // Store eslint results as annotations
            let annotations = []
            try {
              const lintResult = require("./lint.json");
              const LEVELS = {
                0: "notice",
                1: "warning",
                2: "failure"
              };
              const withErrorOrWarning = lintResult.filter(r => r.errorCount > 0 || r.fatalErrorCount > 0 || r.warningCount > 0);
              annotations = withErrorOrWarning.flatMap(({ filePath, messages }) =>
                messages.map((m) => {
                  const sameLine = m.line === m.endLine;
                  return {
                    path: path.relative(process.env.GITHUB_WORKSPACE, filePath),
                    start_line: m.line,
                    end_line: m.endLine,
                    // Annotations only support start_column and end_column on the same line. Omit this parameter if start_line and end_line have different values.
                    // https://docs.github.com/en/rest/reference/checks#create-a-check-run
                    start_column: sameLine ? m.column : undefined,
                    end_column: sameLine ? m.endColumn : undefined,
                    annotation_level: LEVELS[m.severity],
                    message: m.message,
                    title: m.ruleId,
                  }
                })
              );
            } catch(error) {
              console.error("Failed processing eslint annotations", error)
            }

            const output = {
              summary,
              annotations,
              actions: [{
                // 20 chars max
                label: "Regen. Screenshots",
                // 20 chars max
                identifier: "regen_screenshots",
                // 40 chars max
                description: "Will regenerate playwright screenshots",
              }],
            };

            fs.writeFileSync("summary.json", JSON.stringify(output), "utf-8");
      - uses: actions/upload-artifact@v3
        name: upload summary
        with:
          name: summary.json
          path: ${{ github.workspace }}/summary.json

  allure-report:
    name: "Allure Reports Export on Server"
    needs: [e2e-tests-linux]
    runs-on: [ledger-live-medium-linux]
    if: ${{ always() && !cancelled() && github.ref_name == 'develop' }}
    steps:
      - name: checkout
        uses: actions/checkout@v4
        with:
          ref: ${{ github.ref_name }}
      - name: Download Allure Report - Linux
        uses: actions/download-artifact@v3
        with:
          name: allure-results-linux
          path: allure-results-linux
      - name: Send Results and Generate Allure Report - Linux
        uses: ./tools/actions/composites/upload-allure-report
        if: always()
        with:
          platform: linux
          login: ${{ secrets.ALLURE_LOGIN }}
          password: ${{ secrets.ALLURE_PASSWORD }}
          path: allure-results-linux
